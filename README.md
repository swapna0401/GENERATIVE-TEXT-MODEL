*COMPANY*   : CODTECH IT SOLUTIONS

*NAME*      : SWAPNA GEDELA

*INTERN ID* : CT06DM1163

*DOMAIN*    : ARTIFICIAL INTELLIGENCE

*DURATION*  : 6 WEEKS

*MENTOR*    : NEELA SANTHOSH


# GENERATIVE TEXT MODEL

## About the Project

This project is a command-line based text generation tool that uses a pre-trained GPT-2 language model from Hugging Face Transformers to generate coherent, multi-paragraph text based on user input prompts. The model is capable of producing well-structured and diverse content on virtually any topic using deep learning-based natural language generation.

It supports interactive text generation with customizable paragraph count and provides an option to save the output to a timestamped file. The generated content can be used for creative writing, content ideation, educational experiments, or exploration of generative AI capabilities.




## Features

- Takes user input prompt and generates coherent paragraphs.
- Uses GPT-2 model via Hugging Face Transformers.
- Allows user to define number of paragraphs.
- Formats text for terminal readability.
- Optionally saves output with prompt to a text file.
- Runs on CPU or GPU (if available).

## How It Works

1. User is prompted to enter a topic or starting sentence.
2. User chooses how many paragraphs to generate.
3. GPT-2 model generates natural-sounding text paragraphs.
4. Output is displayed in the terminal and optionally saved.


### Prerequisites

Ensure you have Python 3.7 or later installed.

Install dependencies using pip:
pip install -r requirements.txt

## Running the Script

To start the generation tool, run:

python text_generator.py

Follow the prompts:

- Enter a topic or sentence.

- Specify the number of paragraphs to generate.

- Choose whether to save the output.

# Result

![Image](https://github.com/user-attachments/assets/d15315d0-8879-4db2-b4a8-773b13dd4cb8)
